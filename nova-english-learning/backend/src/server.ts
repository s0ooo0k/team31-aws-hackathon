import express from "express";
import http from "http";
import path from "path";
import cors from "cors";
import { Server } from "socket.io";
import dotenv from "dotenv";
import {
  BedrockRuntimeClient,
  InvokeModelCommand,
} from "@aws-sdk/client-bedrock-runtime";
import { NovaSonicBidirectionalStreamClient } from "./client";
import { ImageCategories, EnglishTutorPrompt, createEvidenceBasedPrompt } from "./consts";
import { Buffer } from "node:buffer";

// .env íŒŒì¼ ë¡œë“œ
dotenv.config();

// Express ì•± ë° ì„œë²„ ìƒì„±
const app = express();
const server = http.createServer(app);
const io = new Server(server, {
  cors: {
    origin: "*",
    methods: ["GET", "POST"],
  },
});

// ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.use(cors());
app.use(express.json());
app.use(express.static(path.join(__dirname, "../../frontend/public")));

// Nova Sonic í´ë¼ì´ì–¸íŠ¸ ìƒì„±
const bedrockClient = new NovaSonicBidirectionalStreamClient({
  requestHandlerConfig: {
    maxConcurrentStreams: 10,
  },
  clientConfig: {
    region: process.env.AWS_REGION || "us-east-1",
    credentials: {
      accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
      secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
    },
  },
});

// Nova Canvas í´ë¼ì´ì–¸íŠ¸ ìƒì„±
const bedrockRuntimeClient = new BedrockRuntimeClient({
  region: process.env.AWS_REGION || "us-east-1",
  credentials: {
    accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
  },
});

// ì„¸ì…˜ ì •ë¦¬ (5ë¶„ ë¹„í™œì„± ì‹œ ìë™ ì¢…ë£Œ)
setInterval(() => {
  console.log("Session cleanup check");
  const now = Date.now();

  bedrockClient.getActiveSessions().forEach((sessionId) => {
    const lastActivity = bedrockClient.getLastActivityTime(sessionId);

    if (now - lastActivity > 5 * 60 * 1000) {
      console.log(
        `Closing inactive session ${sessionId} after 5 minutes of inactivity`
      );
      try {
        bedrockClient.forceCloseSession(sessionId);
      } catch (error) {
        console.error(
          `Error force closing inactive session ${sessionId}:`,
          error
        );
      }
    }
  });
}, 60000);

// API ë¼ìš°íŠ¸ë“¤
app.get("/health", (req, res) => {
  res.status(200).json({ status: "ok", timestamp: new Date().toISOString() });
});

// ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ
app.get("/api/categories", (req, res) => {
  res.json({
    success: true,
    data: ImageCategories.map((cat) => ({
      id: cat.id,
      name: cat.name,
      description: cat.description,
      imageCount: cat.images.length,
    })),
  });
});

// ì¹´í…Œê³ ë¦¬ë³„ ì´ë¯¸ì§€ ì¡°íšŒ
app.get("/api/categories/:categoryId/images", (req, res) => {
  const { categoryId } = req.params;
  const category = ImageCategories.find((cat) => cat.id === categoryId);

  if (!category) {
    return res.status(404).json({
      success: false,
      error: "Category not found",
    });
  }

  res.json({
    success: true,
    data: {
      category: category.name,
      images: category.images,
    },
  });
});

// ëœë¤ ì´ë¯¸ì§€ ì„ íƒ
app.get("/api/images/random", (req, res) => {
  const allImages = ImageCategories.flatMap((cat) =>
    cat.images.map((img) => ({
      ...img,
      category: cat.name,
      categoryId: cat.id,
    }))
  );

  const randomImage = allImages[Math.floor(Math.random() * allImages.length)];

  res.json({
    success: true,
    data: randomImage,
  });
});

// Nova Pro ê¸°ë°˜ ì¦ê±° ê¸°ë°˜ í‰ê°€
app.post('/api/evaluate', async (req, res) => {
  try {
    const { imageId, userMessages, conversationHistory } = req.body;
    
    if (!imageId || !userMessages) {
      return res.status(400).json({
        success: false,
        error: 'Image ID and user messages are required'
      });
    }

    const imageData = ImageCategories.flatMap(cat => cat.images)
      .find(img => img.imageId === imageId);
    
    if (!imageData || !imageData.evaluationCriteria) {
      return res.status(404).json({
        success: false,
        error: 'Image or evaluation criteria not found'
      });
    }

    const userText = userMessages.join(' ');
    const responseCount = userMessages.length;
    
    // ì¦ê±° ê¸°ë°˜ í‰ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„±
    const evaluationPrompt = `You are an expert English learning evaluator. Analyze the user's description and provide evidence-based feedback in Korean for the content, but keep the category titles in English.

Evaluation Framework:
1. âœ… STRENGTHS - ì‚¬ìš©ìê°€ ì˜í•œ ì  (ì‚¬ìš©ìì˜ ì‹¤ì œ ë‹µë³€ì—ì„œ êµ¬ì²´ì ì¸ ê·¼ê±° ì œì‹œ)
2. ğŸ“ˆ IMPROVEMENTS - ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­ (ëˆ„ë½ëœ ë¶€ë¶„ì˜ êµ¬ì²´ì ì¸ ì˜ˆì‹œ)
3. ğŸ’¡ ALTERNATIVES - ë” ë‚˜ì€ í‘œí˜„ ë°©ë²• (êµ¬ì²´ì ì¸ ëŒ€ì•ˆ ì œì‹œ)

IMPORTANT: Every point must include specific evidence from the user's actual words or reference what they described/missed. All feedback content should be in Korean, but keep the JSON structure and category titles in English.

User Response Analysis:
- Number of responses: ${responseCount}
- Combined text: "${userText}"

Reference Image Description:
${imageData.evaluationCriteria.detailedDescription}

Key Elements to Look For:
${imageData.evaluationCriteria.keyElements.join(', ')}

Analyze what the user mentioned vs. what they missed, and provide specific evidence for each point.

Provide response in this JSON format:
{
  "accuracy": 85,
  "completeness": 70,
  "vocabulary": 80,
  "detail": 75,
  "strengths": [
    {
      "point": "ìƒ‰ìƒì„ ì •í™•í•˜ê²Œ ì‹ë³„í•˜ê³  í‘œí˜„í–ˆìŠµë‹ˆë‹¤",
      "evidence": "ë‹µë³€ì—ì„œ 'silver laptop'ì´ë¼ê³  ë§ì”€í•˜ì…¨ëŠ”ë°, ì´ëŠ” ì‹œê°ì  ì„¸ë¶€ì‚¬í•­ì— ëŒ€í•œ ì£¼ì˜ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤"
    }
  ],
  "improvements": [
    ${responseCount <= 5 ? `{
      "point": "ë” ë§ì€ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤",
      "evidence": "í˜„ì¬ ${responseCount}ê°œì˜ ë‹µë³€ë§Œ ì œê³µí•˜ì…¨ëŠ”ë°, ì´ë¯¸ì§€ë¥¼ ì¶©ë¶„íˆ ì„¤ëª…í•˜ê¸°ì— ë¶€ì¡±í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ ì„¸ë¶€ì‚¬í•­ì„ ë” ìì„¸íˆ ê´€ì°°í•˜ê³  ìµœì†Œ 8-10ê°œì˜ ë‹µë³€ìœ¼ë¡œ í™•ì¥í•´ë³´ì„¸ìš”."
    },` : ''}
    {
      "point": "êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ì„ ì¶”ê°€í•´ë³´ì„¸ìš”",
      "evidence": "ê¸°ë³¸ì ì¸ ìš”ì†ŒëŠ” ì–¸ê¸‰í•˜ì…¨ì§€ë§Œ ìƒ‰ìƒ, ì¬ì§ˆ, ìœ„ì¹˜ ê´€ê³„ ë“± ë” êµ¬ì²´ì ì¸ ë¬˜ì‚¬ê°€ í•„ìš”í•©ë‹ˆë‹¤"
    }
  ],
  "alternatives": [
    {
      "original": "There are people",
      "better": "Customers are working on their laptops",
      "reason": "ë” êµ¬ì²´ì ì´ê³  ìƒìƒí•œ í‘œí˜„ì…ë‹ˆë‹¤"
    }
  ],
  "feedback": "ì‚¬ìš©ìì˜ ì‹¤ì œ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì „ë°˜ì ì¸ í‰ê°€ (í•œêµ­ì–´ë¡œ)"
}`;

    const command = new InvokeModelCommand({
      modelId: 'amazon.nova-pro-v1:0',
      contentType: 'application/json',
      accept: 'application/json',
      body: JSON.stringify({
        messages: [{
          role: 'user',
          content: [{ text: evaluationPrompt }]
        }],
        inferenceConfig: {
          maxTokens: 1500,
          temperature: 0.3,
          topP: 0.9
        }
      })
    });

    const response = await bedrockRuntimeClient.send(command);
    const responseBody = JSON.parse(Buffer.from(response.body).toString('utf-8'));
    const aiResponse = responseBody.output.message.content[0].text;
    
    // JSON íŒŒì‹±
    const jsonMatch = aiResponse.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('Invalid AI response format');
    }
    
    const evaluation = JSON.parse(jsonMatch[0]);
    // ë‹µë³€ ê°œìˆ˜ê°€ 5ê°œ ì´í•˜ì¼ ë•Œ ì ìˆ˜ ì¡°ì •
    let adjustedScores = {
      accuracy: evaluation.accuracy,
      completeness: evaluation.completeness,
      vocabulary: evaluation.vocabulary,
      detail: evaluation.detail
    };
    
    if (userMessages.length <= 5) {
      // ë‹µë³€ì´ ë¶€ì¡±í•  ë•Œ completenessì™€ detail ì ìˆ˜ë¥¼ ë‚®ì¶¤
      adjustedScores.completeness = Math.max(50, adjustedScores.completeness - 15);
      adjustedScores.detail = Math.max(50, adjustedScores.detail - 10);
    }
    
    const totalScore = Math.round((adjustedScores.accuracy + adjustedScores.completeness + adjustedScores.vocabulary + adjustedScores.detail) / 4);
    
    res.json({
      success: true,
      data: {
        totalScore,
        breakdown: {
          accuracy: adjustedScores.accuracy,
          completeness: adjustedScores.completeness,
          vocabulary: adjustedScores.vocabulary,
          detail: adjustedScores.detail
        },
        feedback: {
          strengths: evaluation.strengths || [],
          improvements: evaluation.improvements || [],
          alternatives: evaluation.alternatives || [],
          overall: evaluation.feedback
        },
        userMessageCount: userMessages.length,
        evidenceBased: true
      }
    });
    
  } catch (error) {
    console.error('Error evaluating with Nova Pro:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to evaluate response',
      details: error instanceof Error ? error.message : String(error)
    });
  }
});

// Stable Diffusion í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
app.get('/test-canvas', (req, res) => {
  const prompt = req.query.prompt || 'a beautiful sunset over the ocean';
  
  res.send(`
    <!DOCTYPE html>
    <html>
    <head>
        <title>Stable Diffusion Test</title>
        <style>
            body { font-family: Arial, sans-serif; padding: 20px; }
            .container { max-width: 800px; margin: 0 auto; }
            input { width: 70%; padding: 10px; margin: 10px 0; }
            button { padding: 10px 20px; background: #007bff; color: white; border: none; cursor: pointer; }
            #result { margin-top: 20px; }
            img { max-width: 100%; border: 1px solid #ddd; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>Stable Diffusion Test</h1>
            <input type="text" id="promptInput" placeholder="Enter image description" value="${prompt}">
            <button onclick="generateImage()">Generate Image</button>
            <div id="result"></div>
        </div>
        
        <script>
            async function generateImage() {
                const prompt = document.getElementById('promptInput').value;
                const result = document.getElementById('result');
                
                result.innerHTML = 'Generating image...';
                
                try {
                    const response = await fetch('/api/images/generate', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ prompt })
                    });
                    
                    const data = await response.json();
                    
                    if (data.success) {
                        result.innerHTML = \`
                            <h3>Generated Image:</h3>
                            <p><strong>Prompt:</strong> \${data.data.prompt}</p>
                            <img src="\${data.data.imageUrl}" alt="Generated image">
                        \`;
                    } else {
                        result.innerHTML = \`<p style="color: red;">Error: \${data.error}</p>\`;
                    }
                } catch (error) {
                    result.innerHTML = \`<p style="color: red;">Error: \${error.message}</p>\`;
                }
            }
        </script>
    </body>
    </html>
  `);
});

// Nova Canvas ì´ë¯¸ì§€ ìƒì„±
app.post("/api/images/generate", async (req, res) => {
  try {
    const { prompt } = req.body;

    if (!prompt || prompt.trim() === "") {
      return res.status(400).json({
        success: false,
        error: "Prompt is required",
      });
    }

    console.log("Generating image with prompt:", prompt);

    const command = new InvokeModelCommand({
      modelId: "amazon.nova-canvas-v1:0",
      body: JSON.stringify({
        taskType: "TEXT_IMAGE",
        textToImageParams: {
          text: prompt,
          negativeText: "blurry, low quality, distorted",
        },
        imageGenerationConfig: {
          numberOfImages: 1,
          height: 512,
          width: 512,
          cfgScale: 8.0,
          seed: Math.floor(Math.random() * 1000000),
        },
      }),
    });

    const response = await bedrockRuntimeClient.send(command);
    const responseBody = JSON.parse(new TextDecoder().decode(response.body));

    if (responseBody.images && responseBody.images.length > 0) {
      const imageBase64 = responseBody.images[0];
      const imageUrl = `data:image/png;base64,${imageBase64}`;
      res.json({
        success: true,
        data: {
          imageUrl: imageUrl,
          prompt: prompt,
        },
      });
    } else {
      throw new Error("No image generated");
    }
  } catch (error) {
    console.error("Error generating image:", error);
    res.status(500).json({
      success: false,
      error: "Failed to generate image",
      details: error instanceof Error ? error.message : String(error),
    });
  }
});

// í˜ì´ì§€ ë¼ìš°íŠ¸ë“¤
app.get("/", (req, res) => {
  res.sendFile(path.join(__dirname, "../../frontend/public/login.html"));
});

app.get("/login", (req, res) => {
  res.sendFile(path.join(__dirname, "../../frontend/public/login.html"));
});

app.get("/categories", (req, res) => {
  res.sendFile(path.join(__dirname, "../../frontend/public/categories.html"));
});

app.get("/study", (req, res) => {
  res.sendFile(path.join(__dirname, "../../frontend/public/study.html"));
});

app.get("/evaluation", (req, res) => {
  res.sendFile(path.join(__dirname, "../../frontend/public/evaluation.html"));
});

// Socket.IO ì—°ê²° ì²˜ë¦¬
io.on("connection", (socket) => {
  console.log("New client connected:", socket.id);

  const sessionId = socket.id;

  try {
    // ì‚¬ìš©ì í…ìŠ¤íŠ¸ ì¶”ì ì„ ìœ„í•œ ë³€ìˆ˜ (ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë³´ë‹¤ ë¨¼ì € ì„ ì–¸)
    let userTextBuffer = "";
    let isUserSpeaking = false;
    let isAISpeaking = false;
    let accumulatedUserText = ""; // ëˆ„ì ëœ ì‚¬ìš©ì ë°œí™”
    let sentMessages = new Set(); // ì¤‘ë³µ ë©”ì‹œì§€ ë°©ì§€ìš© Set

    // Nova Sonic ì„¸ì…˜ ìƒì„±
    const session = bedrockClient.createStreamSession(sessionId);
    bedrockClient.initiateSession(sessionId);

    // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
    session.onEvent("contentStart", (data) => {
      console.log("ğŸ¬ contentStart:", data);
      console.log(
        "ğŸ” Current state - isUserSpeaking:",
        isUserSpeaking,
        "isAISpeaking:",
        isAISpeaking
      );

      // AIê°€ ë§í•˜ê¸° ì‹œì‘í•  ë•Œ - ì‚¬ìš©ì ë°œí™” ì¢…ë£Œ ì²˜ë¦¬ ë¨¼ì €
      if (data.type === "TEXT" && data.role === "ASSISTANT") {
        console.log(
          "ğŸ” Checking if user was speaking - isUserSpeaking:",
          isUserSpeaking,
          "bufferLength:",
          userTextBuffer.trim().length
        );

        // ì‚¬ìš©ìê°€ ë§í•˜ê³  ìˆì—ˆë‹¤ë©´ ë¨¼ì € ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬
        if (isUserSpeaking && userTextBuffer.trim().length > 3) {
          const currentUserText = userTextBuffer.trim();
          console.log("ğŸ¨ User finished speaking:", currentUserText);

          // ì¸ì‚¬ë§ê³¼ ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ ì œê±°
          const cleanedText = filterAndCleanText(currentUserText);

          if (cleanedText.trim().length === 0) {
            console.log(
              "âŒ All text was filtered out (greetings/fillers only), skipping image generation"
            );
          } else if (cleanedText.trim().length >= 8) {
            // ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ ë‚¨ì•„ìˆìœ¼ë©´ ëˆ„ì í•˜ê³  ì´ë¯¸ì§€ ìƒì„±
            accumulatedUserText += " " + cleanedText;
            accumulatedUserText = accumulatedUserText.trim();

            console.log("ğŸ“ Accumulated user text:", accumulatedUserText);
            const imagePrompt = createImagePrompt(accumulatedUserText);
            console.log("ğŸ–¼ï¸ Generated image prompt:", imagePrompt);

            generateImageFromUserText(socket, imagePrompt, cleanedText);
          } else {
            console.log(
              "âŒ Cleaned text too short, skipping image generation. Length:",
              cleanedText.length
            );
          }

          userTextBuffer = "";
          console.log("ğŸ—‘ï¸ User text buffer cleared");
        } else {
          console.log(
            "âŒ No image generation - isUserSpeaking:",
            isUserSpeaking,
            "bufferLength:",
            userTextBuffer.trim().length
          );
        }

        isAISpeaking = true;
        isUserSpeaking = false;
        console.log(
          "ğŸ¤– AI started speaking - isAISpeaking set to true, isUserSpeaking set to false"
        );
      }

      socket.emit("contentStart", data);
    });

    session.onEvent("textOutput", (data) => {
      console.log("ğŸ’¬ Text output:", data.content);
      console.log(
        "ğŸ” State check - isUserSpeaking:",
        isUserSpeaking,
        "isAISpeaking:",
        isAISpeaking,
        "role:",
        data.role
      );

      // ì¤‘ë³µ ë©”ì‹œì§€ ë°©ì§€
      const messageKey = `${data.role}:${data.content}`;
      if (sentMessages.has(messageKey)) {
        console.log("ğŸš« Duplicate message blocked:", messageKey);
        return;
      }
      sentMessages.add(messageKey);
      
      // Set í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
      if (sentMessages.size > 50) {
        const firstKey = Array.from(sentMessages)[0];
        sentMessages.delete(firstKey);
      }

      // ì—­í•  ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì/AI êµ¬ë¶„
      if (data.role === "USER" && data.content) {
        userTextBuffer += data.content + " ";
        console.log("ğŸ‘¤ User text detected:", data.content);
        console.log("ğŸ“ Current userTextBuffer:", userTextBuffer.trim());
        console.log("ğŸ“ Current accumulated text:", accumulatedUserText);

        // ì‚¬ìš©ìê°€ ë§í•˜ê³  ìˆìŒì„ í‘œì‹œ
        if (!isUserSpeaking) {
          isUserSpeaking = true;
          console.log("ğŸ¤ Setting isUserSpeaking to true");
        }

        // ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
        socket.emit("userTextDetected", {
          text: data.content,
          fullBuffer: userTextBuffer.trim(),
        });
      } else if (data.role === "ASSISTANT") {
        console.log("ğŸ¤– AI text output, ignoring for image generation");
      } else {
        console.log(
          "âŒ Text ignored - role:",
          data.role,
          "hasContent:",
          !!data.content
        );
      }

      socket.emit("textOutput", data);
    });

    session.onEvent("audioOutput", (data) => {
      console.log("Audio output received, sending to client");
      socket.emit("audioOutput", data);
    });

    session.onEvent("error", (data) => {
      console.error("Error in session:", data);
      socket.emit("error", data);
    });

    session.onEvent("contentEnd", (data) => {
      console.log("ğŸ Content end received:", data);
      console.log(
        "ğŸ” State at contentEnd - isUserSpeaking:",
        isUserSpeaking,
        "isAISpeaking:",
        isAISpeaking
      );
      console.log("ğŸ“ Current userTextBuffer:", userTextBuffer.trim());

      if (data.type === "TEXT") {
        if (isAISpeaking && data.role === "ASSISTANT") {
          // AI ë°œí™” ì¢…ë£Œ
          isAISpeaking = false;
          console.log("ğŸ¤– AI finished speaking - isAISpeaking set to false");
        }

        // barge-in ì²˜ë¦¬
        if (data.stopReason === "INTERRUPTED") {
          console.log("âš¡ Speech was interrupted (barge-in)");
          isAISpeaking = false;
        }
      }

      socket.emit("contentEnd", data);
    });

    session.onEvent("streamComplete", () => {
      console.log("Stream completed for client:", socket.id);
      socket.emit("streamComplete");
    });

    // ì˜¤ë””ì˜¤ ì…ë ¥ ì²˜ë¦¬
    socket.on("audioInput", async (audioData) => {
      try {
        const audioBuffer =
          typeof audioData === "string"
            ? Buffer.from(audioData, "base64")
            : Buffer.from(audioData);

        // ì‚¬ìš©ìê°€ ë§í•˜ê¸° ì‹œì‘
        if (!isUserSpeaking && !isAISpeaking) {
          isUserSpeaking = true;
          console.log("ğŸ¤ User started speaking - isUserSpeaking set to true");
        }

        await session.streamAudio(audioBuffer);
      } catch (error) {
        console.error("âŒ Error processing audio:", error);
        socket.emit("error", {
          message: "Error processing audio",
          details: error instanceof Error ? error.message : String(error),
        });
      }
    });

    // í”„ë¡¬í”„íŠ¸ ì‹œì‘
    socket.on("promptStart", async () => {
      try {
        console.log("Prompt start received");
        await session.setupPromptStart();
      } catch (error) {
        console.error("Error processing prompt start:", error);
        socket.emit("error", {
          message: "Error processing prompt start",
          details: error instanceof Error ? error.message : String(error),
        });
      }
    });

    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    socket.on("systemPrompt", async (data) => {
      try {
        console.log("System prompt received", data);
        await session.setupSystemPrompt(undefined, data);
      } catch (error) {
        console.error("Error processing system prompt:", error);
        socket.emit("error", {
          message: "Error processing system prompt",
          details: error instanceof Error ? error.message : String(error),
        });
      }
    });

    // ì˜¤ë””ì˜¤ ì‹œì‘
    socket.on("audioStart", async () => {
      try {
        console.log("Audio start received");
        await session.setupStartAudio();
      } catch (error) {
        console.error("Error processing audio start:", error);
        socket.emit("error", {
          message: "Error processing audio start",
          details: error instanceof Error ? error.message : String(error),
        });
      }
    });

    // ì˜¤ë””ì˜¤ ì¤‘ì§€
    socket.on("stopAudio", async () => {
      try {
        console.log("Stop audio requested");
        await session.endAudioContent();
        await session.endPrompt();
        await session.close();
      } catch (error) {
        console.error("Error processing stop audio:", error);
        socket.emit("error", {
          message: "Error processing stop audio",
          details: error instanceof Error ? error.message : String(error),
        });
      }
    });

    // ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
    socket.on("setImageContext", async (imageData) => {
      try {
        console.log("Setting image context:", imageData);

        const contextualPrompt =
          EnglishTutorPrompt +
          `\n\nImage Context: ${imageData.description}\n` +
          `Guiding Questions: ${imageData.guidingQuestions ? imageData.guidingQuestions.join(", ") : "What do you see in this image?"}\n\n` +
          `Start by encouraging the user to describe what they see in the image.`;

        socket.emit("contextSet", { success: true });
      } catch (error) {
        console.error("Error setting image context:", error);
        socket.emit("error", {
          message: "Error setting image context",
          details: error instanceof Error ? error.message : String(error),
        });
      }
    });

    // ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ìƒì„±
    socket.on("generateImage", async (data) => {
      try {
        const { prompt } = data;
        console.log("Socket image generation request:", prompt);

        const imagePrompt = createImagePrompt(prompt);
        await generateImageFromUserText(socket, imagePrompt, prompt);

      } catch (error) {
        console.error("Error generating image via socket:", error);
        socket.emit("imageGenerated", {
          success: false,
          error: error instanceof Error ? error.message : String(error),
        });
      }
    });

    // ì—°ê²° í•´ì œ ì²˜ë¦¬
    socket.on("disconnect", async () => {
      console.log("Client disconnected:", socket.id);

      // ì„¸ì…˜ ë³€ìˆ˜ ì´ˆê¸°í™”
      userTextBuffer = "";
      accumulatedUserText = "";
      isUserSpeaking = false;
      isAISpeaking = false;
      sentMessages.clear(); // Set ì´ˆê¸°í™”

      if (bedrockClient.isSessionActive(sessionId)) {
        try {
          console.log(`Cleaning up session: ${socket.id}`);

          const cleanupPromise = Promise.race([
            (async () => {
              await session.endAudioContent();
              await session.endPrompt();
              await session.close();
            })(),
            new Promise((_, reject) =>
              setTimeout(
                () => reject(new Error("Session cleanup timeout")),
                3000
              )
            ),
          ]);

          await cleanupPromise;
          console.log(`Successfully cleaned up session: ${socket.id}`);
        } catch (error) {
          console.error(`Error cleaning up session: ${socket.id}`, error);
          try {
            bedrockClient.forceCloseSession(sessionId);
          } catch (e) {
            console.error(`Failed force close for session: ${sessionId}`, e);
          }
        }
      }
    });
  } catch (error) {
    console.error("Error creating session:", error);
    socket.emit("error", {
      message: "Failed to initialize session",
      details: error instanceof Error ? error.message : String(error),
    });
    socket.disconnect();
  }
});

// ì´ë¯¸ì§€ ìƒì„± í—¬í¼ í•¨ìˆ˜ë“¤
function filterAndCleanText(text: string): string {
  // ì¸ì‚¬ë§ê³¼ ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ë“¤ ì œê±°
  const skipWords = [
    "hi",
    "hello",
    "hey",
    "good morning",
    "good afternoon",
    "good evening",
    "um",
    "uh",
    "er",
    "ah",
    "oh",
    "hmm",
    "hm",
    "erm",
    "ehm",
    "thank you",
    "thanks",
    "please",
    "excuse me",
    "sorry",
    "yes",
    "no",
    "yeah",
    "yep",
    "nope",
    "okay",
    "ok",
    "alright",
  ];

  let cleanedText = text;

  // ê° ìŠ¤í‚µ ë‹¨ì–´ë¥¼ ì œê±°
  skipWords.forEach((word) => {
    const regex = new RegExp(`\\b${word}\\b`, "gi");
    cleanedText = cleanedText.replace(regex, "").trim();
  });

  // ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì •ë¦¬
  cleanedText = cleanedText.replace(/\s+/g, " ").trim();
  // ë¬¸ì¥ë¶€í˜¸ ì •ë¦¬
  cleanedText = cleanedText.replace(/[,.!?]+/g, "").trim();

  console.log("ğŸ§™ Original text:", text);
  console.log("ğŸ§™ Cleaned text:", cleanedText);

  return cleanedText;
}

function createImagePrompt(userText: string): string {
  // ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ ìƒì„±ì— ì í•©í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
  const cleanText = userText.toLowerCase().trim();

  // ê¸°ë³¸ ìŠ¤íƒ€ì¼ê³¼ í’ˆì§ˆ í–¥ìƒ í‚¤ì›Œë“œ ì¶”ê°€
  return `${cleanText}, realistic style, clear details, good lighting, high quality, photographic, detailed`;
}

async function generateImageFromUserText(
  socket: any,
  imagePrompt: string,
  originalText: string
) {
  try {
    console.log("ğŸ¨ Starting image generation...");
    console.log("ğŸ–¼ï¸ Enhanced prompt:", imagePrompt);
    console.log("ğŸ“ Original text:", originalText);

    const command = new InvokeModelCommand({
      modelId: "amazon.nova-canvas-v1:0",
      body: JSON.stringify({
        taskType: "TEXT_IMAGE",
        textToImageParams: {
          text: imagePrompt,
          negativeText: "blurry, low quality, distorted, text, words, letters",
        },
        imageGenerationConfig: {
          numberOfImages: 1,
          height: 512,
          width: 512,
          cfgScale: 8.0,
          seed: Math.floor(Math.random() * 1000000),
        },
      }),
    });

    console.log("ğŸ“¡ Sending request to Nova Canvas...");
    const response = await bedrockRuntimeClient.send(command);
    console.log("âœ… Received response from Nova Canvas");

    const responseBody = JSON.parse(new TextDecoder().decode(response.body));

    if (responseBody.images && responseBody.images.length > 0) {
      const imageBase64 = responseBody.images[0];
      const imageUrl = `data:image/png;base64,${imageBase64}`;

      console.log("ğŸ‰ Image generated successfully! Sending to client...");
      socket.emit("imageGenerated", {
        success: true,
        imageUrl: imageUrl,
        prompt: imagePrompt,
        originalText: originalText,
        isAutoGenerated: true,
      });
    } else {
      console.log("âŒ No images in response body");
      throw new Error("No image generated");
    }
  } catch (error) {
    console.error("âŒ Error in generateImageFromUserText:", error);
    socket.emit("imageGenerated", {
      success: false,
      error: error instanceof Error ? error.message : String(error),
      originalText: originalText,
    });
  }
}

// ì„œë²„ ì‹œì‘
const PORT = process.env.PORT || 3000;
server.listen(PORT, () => {
  console.log(`Nova English Learning Server listening on port ${PORT}`);
  console.log(`Open http://localhost:${PORT} to access the application`);
});

// ì¢…ë£Œ ì²˜ë¦¬
process.on("SIGINT", async () => {
  console.log("Shutting down server...");

  const forceExitTimer = setTimeout(() => {
    console.error("Forcing server shutdown after timeout");
    process.exit(1);
  }, 5000);

  try {
    await new Promise((resolve) => io.close(resolve));
    console.log("Socket.IO server closed");

    const activeSessions = bedrockClient.getActiveSessions();
    console.log(`Closing ${activeSessions.length} active sessions...`);

    await Promise.all(
      activeSessions.map(async (sessionId) => {
        try {
          await bedrockClient.closeSession(sessionId);
          console.log(`Closed session ${sessionId} during shutdown`);
        } catch (error) {
          console.error(
            `Error closing session ${sessionId} during shutdown:`,
            error
          );
          bedrockClient.forceCloseSession(sessionId);
        }
      })
    );

    await new Promise((resolve) => server.close(resolve));
    clearTimeout(forceExitTimer);
    console.log("Server shut down");
    process.exit(0);
  } catch (error) {
    console.error("Error during server shutdown:", error);
    process.exit(1);
  }
});
